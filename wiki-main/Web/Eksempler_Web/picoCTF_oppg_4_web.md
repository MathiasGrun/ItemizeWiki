# PicoCTF Web Exploit oppg 4. 
"Can you find the robots?" er oppgavenavnet. Her trenger vi informasjon om en viktig ting. Som nevnt, kjører en webpage på en server. En webpage er delt inn i mange websites. Det har seg og slik at det finnes mange tjenester (som f.eks. Google) som har kapasitet til å lete etter informasjon overalt på internettet. For å forhindre at f.eks. Google konstant skal se gjennom absolutt alle websitesene dine, eller pathene til de forskjellige filene, bruker vi det som kalles en "_robots.txt_"-fil. Dette er en egen fil man kan ha på nettsiden. Denne filen er kun en tekstfil men forteller da Google sine "web crawlers" hvilke filer på din server de har lov til å søke seg gjennom. På de aller fleste nettsider finnes det en robots.txt-fil. Man kan se på ntnu.no/robots.txt for å se hvilke filer de ikke ønsker at Web Crawlers skal søke gjennom. 
Tilbake til oppgaven: Dersom vi skriver inn robots.txt på slutten av URL'en til oppgaven ser vi hva som er "Disallowed". Vi ser at det er en html-fil. Vi kan erstatte robots.txt med denne for å komme inn på html-filen. Der finner vi flagget: _picoCTF{ca1cu1at1ng_Mach1n3s_e0779}_.